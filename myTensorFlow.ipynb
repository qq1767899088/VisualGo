{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1nCWE1b1ERv-7cjCVZsKL4CFdta0lSKZb",
      "authorship_tag": "ABX9TyOoJ644RNQRivYBHhe79Pgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qq1767899088/VisualGo/blob/main/myTensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /content/drive/MyDrive/visualGoDataset/VisualGo/ /content/myhome\n",
        "%cd /content/myhome\n",
        "!ls "
      ],
      "metadata": {
        "id": "UdvzLsvtAu9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python myTensorFlow.py"
      ],
      "metadata": {
        "id": "19wmohomBYzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ~/.keras/datasets/mnist.npz ."
      ],
      "metadata": {
        "id": "3mkvscO8hzKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "f3lUzLjsmust"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oEmgFLhmUJi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import sys\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n",
        "b = numpy.load(\"mnist.npz\")\n",
        "print(b.files)\n",
        "\n",
        "print(b[\"x_tes\"t\"][0])"
      ],
      "metadata": {
        "id": "1OqLBNxRm39W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python myParseData.py"
      ],
      "metadata": {
        "id": "sP5W4mJMp2gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from skimage.draw import polygon2mask, polygon, polygon_perimeter\n",
        "\n",
        "from scripts.transformers import MaskTransformer, PerspectiveTransformer, ThreasholdTransformer\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "folder = \"data/board_masks/upload/\"\n",
        "\n",
        "baseFile = \"data/result.json\"\n",
        "image_size = 128\n",
        "# define a dataset class for the Dataloaders\n",
        "basePath = folder\n",
        "imageSize = image_size\n",
        "\n",
        "# load the dataset\n",
        "with open(baseFile) as json_file:\n",
        "    jsonData = json.load(json_file)\n",
        "\n",
        "images = []\n",
        "\n",
        "masks = []\n",
        "\n",
        "# save every image and ground truth mask\n",
        "p = jsonData[42]\n",
        "data = p[\"data\"]\n",
        "imagePath = data[\"image\"]\n",
        "#img = np.array(Image.open(basePath + os.path.basename(imagePath)))\n",
        "import matplotlib.image as mpimg\n",
        "img = np.array(Image.open(basePath + os.path.basename(imagePath))) \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y = np.array(p[\"completions\"][0][\"result\"][0][\"value\"][\"points\"])\n",
        "#mask = polygon2mask((800,800), y*8).astype(bool).T\n",
        "print(img)\n",
        "print(y)\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6ghdGPFT72uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pycat myParseData.py"
      ],
      "metadata": {
        "id": "jgBBU5t9tBlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "P0zSckxFu34u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%loadpy myParseData.py"
      ],
      "metadata": {
        "id": "IF3EfUDFwa8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%lsmagic"
      ],
      "metadata": {
        "id": "sDCEUOvux4n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load --help\n"
      ],
      "metadata": {
        "id": "9OBcQQ8M1nSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python myCnnNet.py"
      ],
      "metadata": {
        "id": "bTAA3jnUo9x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_model_summary\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from scripts.unet import UNet\n",
        "from scripts.transformers import MaskTransformer, PerspectiveTransformer, ThreasholdTransformer\n",
        "from scripts.dataloaders import PositionDataset\n",
        "\n",
        "from pytorch_model_summary import summary\n",
        "\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tf2\n",
        "print(tf.__version__)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(in_channels=3, n_classes=2, wf=5, depth=4, padding=True, up_mode='upsample')\n",
        "model.load_state_dict(torch.load(\"state_dicts/checkpoint.pth\",device))\n",
        "model.eval()\n",
        "print(summary(model, torch.zeros((1, 3, 128, 128)), show_input=False))\n",
        "pd = PositionDataset(\"data/goBoards/training/\", 128, model)\n"
      ],
      "metadata": {
        "id": "qK0wNusjplDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(pd[42][1])"
      ],
      "metadata": {
        "id": "maW2L2VX7ZdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = []\n",
        "y3 = []\n",
        "for i in pd:\n",
        "\tx3.append(i[0].tolist())\n",
        "\ty3.append(i[1].tolist())\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n"
      ],
      "metadata": {
        "id": "MrOCY97yYoMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.array(x3)\n",
        "x = np.moveaxis(x1,1,3)\n",
        "y1 = np.array(y3)\n",
        "y = y1.reshape(y1.shape[0],-1)\n",
        "print(x.shape)\t\n",
        "print(y1.shape)\t"
      ],
      "metadata": {
        "id": "ii5M4F5MZWEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x[42][7:120,5:120])"
      ],
      "metadata": {
        "id": "mggKa5vMXqA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(y1[42])"
      ],
      "metadata": {
        "id": "QdVBVlLZbSrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#myData = tf2.datasets.mnist\n",
        "# y:ground truth;x:model argument ,ie tensors to be feed to the model function\n",
        "#(x,y),(x2,y2) = myData.load_data()\n",
        "#x,x2 = x/255.0,x2/255.0\n",
        "\n",
        "#a = tf2.layers.Flatten(input_shape=(28,28) ) \n",
        "a = tf2.layers.Conv2D(128,kernel_size = 3,activation = \"relu\", input_shape=(128,128,3) ) \n",
        "a2 = tf2.layers.MaxPooling2D((2, 2)) \n",
        "a3 = tf2.layers.Conv2D(128,kernel_size = 3,activation = \"relu\") \n",
        "a4 = tf2.layers.Flatten() \n",
        "\n",
        "\n",
        "a5 = tf2.layers.Dense(128,activation='relu')\n",
        "a6 = tf2.layers.Dropout(0.2) \n",
        "a7 = tf2.layers.Dense(169,activation='softmax') \n",
        "myModel = tf2.models.Sequential([a,a2,a3,a4,a5,a6,a7 ])\n",
        "# p prediction\n",
        "#p = myModel(x[:1]).numpy()\n",
        "#p\n",
        "#tf.nn.softmax(p).numpy()\n",
        "\n",
        "lossFunction = tf2.losses.CategoricalCrossentropy(True)\n",
        "#lossFunction(y[:1],p).numpy()\n",
        "# \"adam\":optimizer;[\"accuracy\"]:metrics\n",
        "myModel.compile(\"adam\",lossFunction,[\"accuracy\"])\n",
        "# 5:epochs\n",
        "myModel.fit(x,y,5)\n"
      ],
      "metadata": {
        "id": "jd0edEeRrcnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "MTFeRidfIGcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJ01u-I6JRRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sgfmill"
      ],
      "metadata": {
        "id": "qts_y-_kLsNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as tf2\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "img1 = cv.imread('sgf1.png')/255.0\n",
        "img2 = cv.imread('sgf2.png')/255.0\n",
        "img3 = cv.imread('sgf3.png')/255.0\n",
        "img4 = cv.imread('sgf4.png')/255.0\n",
        "img5 = cv.imread('sgf5.png')/255.0\n",
        "#cv.imshow('Original', img)\n",
        "#time.sleep(20)\n",
        "\n",
        "#img3 = img[0:1600,0:1600]\n",
        "#img4 = img[227:1230,107:1020]\n",
        "#img4 = img[335:1230,125:1020]\n",
        "\n",
        "(x,y),(x2,y2)=(43,243),(1360,1560)\n",
        "mycrop = img1[y:y2,x:x2]\n",
        "l=(x2-x)/36\n",
        "l2 = int(2*l)\n",
        "def getP(x3,y3):\n",
        "\ta2 = int(x3-l)\n",
        "\tb2 = int(y3-l)\n",
        "\treturn [a2,b2,a2+l2,b2+l2]\n",
        "#mask = cv.circle(blank, center_coordinates, radius, 255, -1)\n",
        "x_train = []\n",
        "def myAppend(img5,x_train3):\n",
        "\tfor b in range(19):\n",
        "\t\tfor a in range(19):\n",
        "\t\n",
        "\t\t\tc = getP(x+2*l*a,y+2*l*b)\n",
        "\t\t\td = img5[c[1]:c[3],c[0]:c[2]]\n",
        "\t\t\tx_train3.append(d)\n",
        "myAppend(img1,x_train);\n",
        "myAppend(img2,x_train);\n",
        "myAppend(img3,x_train);\n",
        "myAppend(img4,x_train);\n",
        "myAppend(img5,x_train);\n",
        "\n",
        "import pandas as pd\n",
        "s = pd.Series(list('abca'))\n",
        "s1=pd.get_dummies(s)\n",
        "print(s1[\"a\"])\n",
        "from sgfmill import sgf\n",
        "mydict = {\"w\":(1,0,0),\"b\":(0,0,1)}\n",
        "def myEncode(z):\n",
        "\treturn mydict[z]\n",
        "import numpy as np\n",
        "y_train = np.full((361*5,3),(0,1,0))\n",
        "def parseSgf(u,v):\n",
        "\twith open(u, \"rb\") as f:\n",
        "\t    game = sgf.Sgf_game.from_bytes(f.read())\n",
        "\twinner = game.get_winner()\n",
        "\tboard_size = game.get_size()\n",
        "\troot_node = game.get_root()\n",
        "\tb_player = root_node.get(\"PB\")\n",
        "\tw_player = root_node.get(\"PW\")\n",
        "\tfor node in game.get_main_sequence():\n",
        "\t    colour, move=node.get_move()\n",
        "\t    #print(move)\n",
        "\t    if move is None:\n",
        "\t        continue\n",
        "\t    row, col = move\n",
        "\t    y_train[v*361+19*(18-row)+col]=myEncode(colour)\n",
        "\n",
        "parseSgf(\"sgf1.sgf\",0)\n",
        "parseSgf(\"sgf2.sgf\",1)\n",
        "parseSgf(\"sgf3.sgf\",2)\n",
        "parseSgf(\"sgf4.sgf\",3)\n",
        "parseSgf(\"sgf5.sgf\",4)\n",
        "\n",
        "print(y_train)\n",
        "#a = tf2.layers.Flatten(input_shape=(28,28) ) \n",
        "a = tf2.layers.Conv2D(128,kernel_size = 3,activation = \"relu\", input_shape=(l2,l2,3) ) \n",
        "a2 = tf2.layers.MaxPooling2D((2, 2)) \n",
        "a3 = tf2.layers.Conv2D(128,kernel_size = 3,activation = \"relu\") \n",
        "a4 = tf2.layers.Flatten() \n",
        "a2 = tf2.layers.Dense(128,activation = \"relu\" ) \n",
        "a3 = tf2.layers.Dropout(0.2) \n",
        "a5 = tf2.layers.Dense(3,activation = \"softmax\",) \n",
        "myModel = tf2.models.Sequential([a,a2,a3,a4,a5 ])\n",
        "# p prediction\n",
        "\n",
        "lossFunction = tf2.losses.CategoricalCrossentropy(False)\n",
        "# \"adam\":optimizer;[\"accuracy\"]:metrics\n",
        "myModel.compile(\"adam\",lossFunction,[\"accuracy\"])\n",
        "x_train2 = np.array(x_train)# 5:epochs\n",
        "myModel.fit(x_train2,y_train,5)\n",
        "\n",
        "w = 550\n",
        "print(len(x_train)); \n",
        "#cv.imshow('Output', x_train[w])\n",
        "print(y_train[w])\n",
        "#cv.imwrite(\"321.png\",resized)\n",
        "#cv.imwrite(\"321.jpg\",resized,[int(cv.IMWRITE_JPEG_QUALITY), 100])\n",
        "#time.sleep(20)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MdUc3tHVJ1J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q=np.empty(1024)\n",
        "q.reshape((-1,2,4,8)).shape"
      ],
      "metadata": {
        "id": "PJx0VqGYdZam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydict2 = [1,0,-1]\n",
        "img9 = cv.imread('sgf9.png')/255.0\n",
        "x_test = []\n",
        "res = []\n",
        "#def mydecode():\n",
        " #   decoded = tf.argmax(one_hot_encoded, axis=1)\n",
        "myAppend(img9,x_test)\n",
        "\n",
        "x_test3=np.array(x_test)\n",
        "print(x_test3.shape)\n",
        "x_test2=x_test3.reshape((-1,19,73,73,3))\n",
        "for i in x_test2:\n",
        "  #print(i)\n",
        "  a5=myModel.predict(i)\n",
        "  #print(a5)\n",
        "  a6 = np.argmax(a5,axis=1)\n",
        "  print(a6)\n",
        "  a7 = map(lambda x:mydict2[x],a6)\n",
        "  #print(list(a7))\n",
        "  res.append(list(a7))\n",
        "  print(res)\n",
        "\n"
      ],
      "metadata": {
        "id": "wfRdnWu7_2KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#res2=np.reshape(np.array(res),(19,19))\n",
        "res2 = res\n",
        "print(res2)\n",
        "plt.imshow(res2)"
      ],
      "metadata": {
        "id": "O2325hnKUghT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img9)"
      ],
      "metadata": {
        "id": "JyOEbtV3U2_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "QY0uPsxc1Nk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train2[22][np.newaxis,...].shape)\n",
        "t=361*4+19*9+9\n",
        "plt.imshow(x_train2[t])\n",
        "print(np.argmax(myModel.predict(x_train2[t][np.newaxis,...])[0]))"
      ],
      "metadata": {
        "id": "jmy1Dl4UQszu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python myTensorFlow.py"
      ],
      "metadata": {
        "id": "J0pxgWfyfUAL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}